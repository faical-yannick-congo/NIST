{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Purpose **\n",
    "- 5000 Random Selection of INS and DEL\n",
    "- Identify and drop any duplications from the random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Imports \n",
    "###################################################\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Data \n",
    "###################################################\n",
    "'''\n",
    "Deletions\n",
    "'''\n",
    "colnames = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "df_DEL_0_1000 = pd.read_table('union_refalt.sort.DEL.1to1000.txt', names=colnames)\n",
    "df_DEL_1001_2000 = pd.read_table('union_refalt.sort.DEL.1001to2000.txt', names=colnames)\n",
    "df_DEL_2001_3000 = pd.read_table('union_refalt.sort.DEL.2001to3000.txt', names=colnames)\n",
    "df_DEL_3001_4000 = pd.read_table('union_refalt.sort.DEL.3001to4000.txt', names=colnames)\n",
    "df_DEL_4001_5000 = pd.read_table('union_refalt.sort.DEL.4001to5000.txt', names=colnames)\n",
    "\n",
    "'''\n",
    "Insertions\n",
    "'''\n",
    "\n",
    "# Strategy 2: Import txt files\n",
    "colnames = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M']\n",
    "df_INS_0_1000 = pd.read_table('union_refalt.sort.INS.1to1000.txt', names=colnames)\n",
    "df_INS_1001_2000 = pd.read_table('union_refalt.sort.INS.1001to2000.txt', names=colnames)\n",
    "df_INS_2001_3000 = pd.read_table('union_refalt.sort.INS.2001to3000.txt', names=colnames)\n",
    "df_INS_3001_4000 = pd.read_table('union_refalt.sort.INS.3001to4000.txt', names=colnames)\n",
    "df_INS_4001_5000 = pd.read_table('union_refalt.sort.INS.4001to5000.txt', names=colnames)\n",
    "\n",
    "'''\n",
    "Additional Data\n",
    "'''\n",
    "df_DEL_2 = pd.read_csv('df_DEL.csv')\n",
    "df_INS_2 = pd.read_csv('df_INS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deletions **\n",
    "Identifiy duplicate entries in deletions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(5001, 13)\n",
      "(4999, 13)\n"
     ]
    }
   ],
   "source": [
    "# 1. Concatenate the dataframes\n",
    "df_DEL = pd.concat([df_DEL_0_1000, df_DEL_1001_2000, df_DEL_2001_3000, df_DEL_3001_4000, df_DEL_4001_5000], axis=0)\n",
    "#Column count\n",
    "print (len(df_DEL.columns))\n",
    "df_DEL.to_csv('df_DEL2.csv', index=False)\n",
    "df_DEL_2 = pd.read_csv('df_DEL.csv')\n",
    "print (df_DEL_2.shape)\n",
    "\n",
    "# 2. Drop Duplicates\n",
    "df_DEL_2.drop_duplicates(keep=False, inplace=True)\n",
    "print (df_DEL_2.shape)\n",
    "df_DEL_2.to_csv('df_DEL_drop_DUP.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Insertions **\n",
    "Identifiy duplicate entries in insertions dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "(5033, 13)\n",
      "(5023, 13)\n"
     ]
    }
   ],
   "source": [
    "# 1. Concatenate the dataframes\n",
    "df_INS = pd.concat([df_INS_0_1000, df_INS_1001_2000, df_INS_2001_3000, df_INS_3001_4000, df_INS_4001_5000], axis=0)\n",
    "#Column count\n",
    "print (len(df_INS.columns))\n",
    "df_INS.to_csv('df_INS2.csv', index=False)\n",
    "df_INS_2 = pd.read_csv('df_INS.csv')\n",
    "print (df_INS_2.shape)\n",
    "\n",
    "# 2. Drop Duplicates\n",
    "df_INS_2.drop_duplicates(keep=False, inplace=True)\n",
    "print (df_INS_2.shape)\n",
    "df_INS_2.to_csv('df_INS_drop_DUP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra rows are reported due to long insertions on mulitple lines of the dataframe"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [NIHFAES]",
   "language": "python",
   "name": "Python [NIHFAES]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
